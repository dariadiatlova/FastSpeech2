seed: 8000
n_gpus: 1
checkpoint_path: "/root/storage/dasha/saved_models/fastspeech/esd/lpips_vctk_finetune_step=200000.ckpt"
vocoder_path: "/root/storage/dasha/saved_models/hifi_torchscript/vctk_esd/HiFi--val_loss=0.1967-epoch=4549.pt"
filepath: null

postprocessing:
  device: "cuda"
  output_mel_dir: "/root/storage/dasha/data/emo-data/postprocessed"
  vocoder_json_dirpath: "/root/storage/dasha/data/emo-data/vocoder_configs"

wandb:
  gt_audio_directory_path: "/root/storage/dasha/data/emo-data/english_esd/preprocessed/trimmed_wav"
  save_dir: null
  progress_bar_refresh_rate: 1
  checkpoint_directory: null
  project: "FS_VCTK_ESD"
  offline: false
  log_every_n_steps: 1
  val_step: 30
  save_step: 50000
  total_step: 200000
  save_last: true

preprocess:
  scale: 7
  device: "cuda"
  batch_size: 64
  sort: true
  drop_last: true
  include_empty_intervals: true
  val_size: 0
  path:
    raw_path: "/root/storage/dasha/data/emo-data/english_esd/preprocessed/trimmed_wav"
    preprocessed_path: "/root/storage/dasha/data/emo-data/english_esd/preprocessed"
    phones_mapping_path: "/root/storage/dasha/data/emo-data/english_esd/esd_phones_mapping.json"
    esd_vctk_speaker_mapping_path: "/root/storage/dasha/data/emo-data/english_esd/vctk_esd_speaker_mapping.json"
    ckpt_path: null
  audio:
    sampling_rate: 16000
    max_wav_value: 32768.0
  stft:
    filter_length: 512
    hop_length: 128
    win_length: 512
  mel:
    n_mel_channels: 80
    mel_fmin: 0
    mel_fmax: 8000 # please set to 8000 for HiFi-GAN vocoder, set to null for MelGAN vocoder
  pitch:
    feature: "phoneme_level" # support 'phoneme_level' or 'frame_level'
    normalization: True
  energy:
    feature: "phoneme_level" # support 'phoneme_level' or 'frame_level'
    normalization: True

model:
  retrain_speaker_embed: false
  old_speaker_count: 108
  emotion: true
  multi_speaker: true
  device: "cuda"
  max_seq_len: 3000

  transformer:
    encoder_layer: 4
    encoder_head: 2
    encoder_hidden: 256
    decoder_layer: 6
    decoder_head: 2
    decoder_hidden: 256
    conv_filter_size: 1024
    conv_kernel_size: [9, 1]
    encoder_dropout: 0.2
    decoder_dropout: 0.2

  variance_predictor:
    filter_size: 256
    kernel_size: 3
    dropout: 0.5

  variance_embedding:
    pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
    energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
    n_bins: 256

  optimizer:
    betas: [0.9, 0.98]
    eps: 0.000000001
    weight_decay: 0.0
    grad_clip_thresh: 1.0
    grad_acc_step: 1
    warm_up_step: 4000
    anneal_steps: [300000, 400000, 500000]
    anneal_rate: 0.3
